{
  "id": "subrun-20250403-053347-vllm-Llama-3-2-1B-generation-throughput-b2c9aaa2",
  "parent_run_id": "run-20250403-053218-vllm-Llama-3-2-1B-conversational-long-context-generation-throughput-4d567aa1",
  "engine": {
    "name": "vllm",
    "type": "vllm",
    "model": "NousResearch/Llama-3.2-1B",
    "status": "running",
    "container_id": "9336b1398857",
    "engine_args": {
      "model": "NousResearch/Llama-3.2-1B",
      "trust-remote-code": true,
      "disable-log-requests": true,
      "dtype": "half"
    },
    "env_vars": {
      "VLLM_USE_V1": "1",
      "VLLM_USAGE_SOURCE": "production-docker-image"
    },
    "full_engine_args": {},
    "full_env_vars": {
      "VLLM_USE_V1": "1",
      "PATH": "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
      "NVARCH": "x86_64",
      "NVIDIA_REQUIRE_CUDA": "cuda>=12.4 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536",
      "NV_CUDA_CUDART_VERSION": "12.4.99-1",
      "NV_CUDA_COMPAT_PACKAGE": "cuda-compat-12-4",
      "CUDA_VERSION": "12.4.0",
      "LD_LIBRARY_PATH": "/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
      "NVIDIA_VISIBLE_DEVICES": "all",
      "NVIDIA_DRIVER_CAPABILITIES": "compute,utility",
      "NV_CUDA_LIB_VERSION": "12.4.0-1",
      "NV_NVTX_VERSION": "12.4.99-1",
      "NV_LIBNPP_VERSION": "12.2.5.2-1",
      "NV_LIBNPP_PACKAGE": "libnpp-12-4=12.2.5.2-1",
      "NV_LIBCUSPARSE_VERSION": "12.3.0.142-1",
      "NV_LIBCUBLAS_PACKAGE_NAME": "libcublas-12-4",
      "NV_LIBCUBLAS_VERSION": "12.4.2.65-1",
      "NV_LIBCUBLAS_PACKAGE": "libcublas-12-4=12.4.2.65-1",
      "NV_LIBNCCL_PACKAGE_NAME": "libnccl2",
      "NV_LIBNCCL_PACKAGE_VERSION": "2.20.5-1",
      "NCCL_VERSION": "2.20.5-1",
      "NV_LIBNCCL_PACKAGE": "libnccl2=2.20.5-1+cuda12.4",
      "NVIDIA_PRODUCT_NAME": "CUDA",
      "NV_CUDA_CUDART_DEV_VERSION": "12.4.99-1",
      "NV_NVML_DEV_VERSION": "12.4.99-1",
      "NV_LIBCUSPARSE_DEV_VERSION": "12.3.0.142-1",
      "NV_LIBNPP_DEV_VERSION": "12.2.5.2-1",
      "NV_LIBNPP_DEV_PACKAGE": "libnpp-dev-12-4=12.2.5.2-1",
      "NV_LIBCUBLAS_DEV_VERSION": "12.4.2.65-1",
      "NV_LIBCUBLAS_DEV_PACKAGE_NAME": "libcublas-dev-12-4",
      "NV_LIBCUBLAS_DEV_PACKAGE": "libcublas-dev-12-4=12.4.2.65-1",
      "NV_CUDA_NSIGHT_COMPUTE_VERSION": "12.4.0-1",
      "NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE": "cuda-nsight-compute-12-4=12.4.0-1",
      "NV_NVPROF_VERSION": "12.4.99-1",
      "NV_NVPROF_DEV_PACKAGE": "cuda-nvprof-12-4=12.4.99-1",
      "NV_LIBNCCL_DEV_PACKAGE_NAME": "libnccl-dev",
      "NV_LIBNCCL_DEV_PACKAGE_VERSION": "2.20.5-1",
      "NV_LIBNCCL_DEV_PACKAGE": "libnccl-dev=2.20.5-1+cuda12.4",
      "LIBRARY_PATH": "/usr/local/cuda/lib64/stubs",
      "DEBIAN_FRONTEND": "noninteractive",
      "UV_HTTP_TIMEOUT": "500",
      "VLLM_USAGE_SOURCE": "production-docker-image"
    },
    "version": "0.8.2",
    "endpoint": "http://localhost:8000",
    "gpu_info": {
      "success": true,
      "container_id": "9336b1398857",
      "container_stats": {
        "cpu_usage": "1.29%",
        "memory_usage": "2.832GiB / 117.9GiB",
        "memory_percent": "2.40%"
      },
      "gpus": [
        {
          "index": 0,
          "name": "NVIDIA A100-SXM4-40GB",
          "memory_total": 39936.0,
          "memory_used": 35873.0,
          "utilization": 0.0
        }
      ]
    }
  },
  "model": "NousResearch/Llama-3.2-1B",
  "benchmark": {
    "type": "generation_throughput",
    "config": {
      "dataset-name": "random",
      "random-input-len": 2000,
      "random-output-len": 100,
      "random-prefix-len": 1000,
      "num-prompts": 50,
      "request-rate": 10
    },
    "command": "python /root/inference-engine-arena/src/benchmarks/benchmark_serving.py --base-url http://localhost:8000 --model NousResearch/Llama-3.2-1B --backend vllm --trust-remote-code --dataset-name random --random-input-len 2000 --random-output-len 100 --random-prefix-len 1000 --num-prompts 50 --request-rate 10 --save-result --result-dir results/run-20250403-053218-vllm-Llama-3-2-1B-conversational-long-context-generation-throughput-4d567aa1/subrun-20250403-053347-vllm-Llama-3-2-1B-generation-throughput-b2c9aaa2 --result-filename raw_result.json",
    "namespace_params": {
      "backend": "vllm",
      "base_url": "http://localhost:8000",
      "host": "127.0.0.1",
      "port": 8000,
      "endpoint": "/v1/completions",
      "dataset_name": "random",
      "dataset_path": null,
      "max_concurrency": null,
      "model": "NousResearch/Llama-3.2-1B",
      "tokenizer": null,
      "use_beam_search": false,
      "num_prompts": 50,
      "logprobs": null,
      "request_rate": 10.0,
      "burstiness": 1.0,
      "seed": 0,
      "trust_remote_code": true,
      "disable_tqdm": false,
      "profile": false,
      "save_result": true,
      "save_detailed": false,
      "metadata": null,
      "result_dir": "results/run-20250403-053218-vllm-Llama-3-2-1B-conversational-long-context-generation-throughput-4d567aa1/subrun-20250403-053347-vllm-Llama-3-2-1B-generation-throughput-b2c9aaa2",
      "result_filename": "raw_result.json",
      "ignore_eos": false,
      "percentile_metrics": "ttft",
      "metric_percentiles": "99",
      "goodput": null,
      "sonnet_input_len": 550,
      "sonnet_output_len": 150,
      "sonnet_prefix_len": 200,
      "sharegpt_output_len": null,
      "random_input_len": 2000,
      "random_output_len": 100,
      "random_range_ratio": 1.0,
      "random_prefix_len": 1000,
      "hf_subset": null,
      "hf_split": null,
      "hf_output_len": null,
      "tokenizer_mode": "auto",
      "served_model_name": null
    }
  },
  "start_time": "2025-04-03T05:33:47.728715",
  "end_time": "2025-04-03T05:34:04.271562",
  "duration_seconds": 16.542847,
  "success": true,
  "metrics": {
    "input_throughput": 24240.53794660024,
    "output_throughput": 635.2636977872369,
    "ttft": 46.48316278001403,
    "tpot": 5.228319752199787,
    "duration": 6.187981484999909,
    "num_prompts": 50,
    "total_input_tokens": 150000,
    "total_output_tokens": 3931
  },
  "exit_code": 0,
  "stdout": "INFO 04-03 05:33:52 [__init__.py:239] Automatically detected platform cuda.\nNamespace(backend='vllm', base_url='http://localhost:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='NousResearch/Llama-3.2-1B', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=True, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/run-20250403-053218-vllm-Llama-3-2-1B-conversational-long-context-generation-throughput-4d567aa1/subrun-20250403-053347-vllm-Llama-3-2-1B-generation-throughput-b2c9aaa2', result_filename='raw_result.json', ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=2000, random_output_len=100, random_range_ratio=1.0, random_prefix_len=1000, hf_subset=None, hf_split=None, hf_output_len=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: 10.0\nBurstiness factor: 1.0 (Poisson process)\nMaximum request concurrency: None\n============ Serving Benchmark Result ============\nSuccessful requests:                     50        \nBenchmark duration (s):                  6.19      \nTotal input tokens:                      150000    \nTotal generated tokens:                  3931      \nRequest throughput (req/s):              8.08      \nOutput token throughput (tok/s):         635.26    \nTotal Token throughput (tok/s):          24875.80  \n---------------Time to First Token----------------\nMean TTFT (ms):                          46.48     \nMedian TTFT (ms):                        37.37     \nP99 TTFT (ms):                           93.63     \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          5.23      \nMedian TPOT (ms):                        4.60      \nP99 TPOT (ms):                           13.05     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           4.92      \nMedian ITL (ms):                         4.39      \nP99 ITL (ms):                            26.54     \n==================================================\n",
  "stderr": "\n  0%|          | 0/50 [00:00<?, ?it/s]\n  2%|\u258f         | 1/50 [00:00<00:24,  2.00it/s]\n  6%|\u258c         | 3/50 [00:00<00:09,  5.11it/s]\n 10%|\u2588         | 5/50 [00:01<00:08,  5.59it/s]\n 12%|\u2588\u258f        | 6/50 [00:01<00:07,  6.26it/s]\n 18%|\u2588\u258a        | 9/50 [00:01<00:07,  5.32it/s]\n 24%|\u2588\u2588\u258d       | 12/50 [00:01<00:05,  7.22it/s]\n 30%|\u2588\u2588\u2588       | 15/50 [00:02<00:03,  9.68it/s]\n 34%|\u2588\u2588\u2588\u258d      | 17/50 [00:02<00:03, 10.51it/s]\n 40%|\u2588\u2588\u2588\u2588      | 20/50 [00:02<00:02, 12.28it/s]\n 46%|\u2588\u2588\u2588\u2588\u258c     | 23/50 [00:02<00:02, 11.48it/s]\n 50%|\u2588\u2588\u2588\u2588\u2588     | 25/50 [00:02<00:01, 12.70it/s]\n 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 27/50 [00:03<00:02,  9.30it/s]\n 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 29/50 [00:03<00:03,  6.62it/s]\n 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 31/50 [00:04<00:02,  6.38it/s]\n 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 32/50 [00:04<00:02,  6.28it/s]\n 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 33/50 [00:04<00:02,  5.78it/s]\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 35/50 [00:04<00:02,  7.08it/s]\n 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 36/50 [00:04<00:02,  6.77it/s]\n 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 39/50 [00:05<00:01,  6.57it/s]\n 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 41/50 [00:05<00:01,  7.08it/s]\n 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 44/50 [00:05<00:00,  7.96it/s]\n 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 46/50 [00:05<00:00,  9.28it/s]\n 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 48/50 [00:06<00:00,  9.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [00:06<00:00,  8.08it/s]\n"
}